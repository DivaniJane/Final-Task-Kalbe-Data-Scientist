# -*- coding: utf-8 -*-
"""Project Machine Learning Kalbe Nutritional.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bbwrOYIBuk4X25Ye-0nhLmZiIuQ7j70t
"""

import pandas as pd
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn import preprocessing
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt
from statsmodels.tsa.arima.model import ARIMA
from pandas.plotting import autocorrelation_plot

import warnings
warnings.filterwarnings('ignore')

customer= pd.read_csv("/content/Customer.csv",delimiter=';')
product= pd.read_csv("/content/Product.csv",delimiter=';')
store= pd.read_csv("/content/Store.csv",delimiter=';')
transaction = pd.read_csv("/content/Transaction.csv",delimiter=';')

customer.shape,product.shape, store.shape, transaction.shape

customer.head()

product.head()

store.head()

transaction.head()

customer['Income'] = customer['Income'].str.replace(',', '.', regex=True).astype(float)

store['Latitude'] = store['Latitude'].replace(',', '.', regex=True).astype(float)
store['Longitude'] = store['Longitude'].str.replace(',', '.', regex=True).astype(float)

transaction['Date'] = pd.to_datetime(transaction['Date'])

print(store['Latitude'].dtype)
print(store['Longitude'].dtype)

merged_data = pd.merge(customer, transaction, on='CustomerID')
merged_data = pd.merge(merged_data, product, on='ProductID')
merged_data = pd.merge(merged_data, store, on='StoreID')
merged_data.head()

regresi = merged_data.groupby(['Date']).agg({'Qty' : 'sum'}).reset_index()
regresi

decomposed = seasonal_decompose(regresi.set_index('Date'))

plt.figure(figsize=(8, 8))

plt.subplot(311)
decomposed.trend.plot(ax=plt.gca())
plt.title('Trend')
plt.subplot(312)
decomposed.seasonal.plot(ax=plt.gca())
plt.title('Seasonality')
plt.subplot(313)
decomposed.resid.plot(ax=plt.gca())
plt.title('Residuals')

plt.tight_layout()

cut_off = round(regresi.shape[0] * 0.9)
df_train = regresi.iloc[:cut_off]
df_test = regresi.iloc[cut_off:].reset_index(drop=True)
df_train.shape, df_test.shape

df_train

df_test

plt.figure(figsize=(20, 5))
sns.lineplot(data=df_train, x=df_train['Date'], y=df_train['Qty']);
sns.lineplot(data=df_test, x=df_test['Date'], y=df_test['Qty'])

autocorrelation_plot(regresi['Qty']);

def rmse(y_actual, y_pred):
    """
    function to calculate RMSE
    """

    print(f'RMSE value {mean_squared_error(y_actual, y_pred)**0.5}')

def eval(y_actual, y_pred):
    """
    function to eval machine learning modelling
    """

    rmse(y_actual, y_pred)
    print(f'MAE value {mean_absolute_error(y_actual, y_pred)}')

#ARIMA
df_train = df_train.set_index('Date')
df_test = df_test.set_index('Date')

y = df_train['Qty']

ARIMAmodel = ARIMA(y, order = (40, 2, 1))
ARIMAmodel = ARIMAmodel.fit()

y_pred = ARIMAmodel.get_forecast(len(df_test))

y_pred_df = y_pred.conf_int()
y_pred_df['predictions'] = ARIMAmodel.predict(start =y_pred_df.index[0], end =y_pred_df.index[-1])
y_pred_df.index = df_test.index
y_pred_out = y_pred_df['predictions']
eval(df_test['Qty'], y_pred_out)

plt.figure(figsize=(20, 5))
plt.plot(df_train['Qty'])
plt.plot(df_test['Qty'], color='red')
plt.plot(y_pred_out, color='black', label = 'ARIMA Predictions')

#Membuat model machine learning clustering
merged_data.head()

merged_data.corr()

df_cluster = merged_data.groupby(['CustomerID']).agg({'TransactionID' : 'count','Qty' : 'sum'}).reset_index()
df_cluster.head()

df_cluster

data_cluster = df_cluster.drop(columns=['CustomerID'])
data_cluster_normalize = preprocessing.normalize(data_cluster)

K = range(2, 8)
fits = []
score = []

for k in K:
      model =KMeans(n_clusters = k, random_state = 0, n_init='auto').fit(data_cluster_normalize)

      fits.append(model)

      score.append(silhouette_score(data_cluster_normalize, model.labels_, metric='euclidean'))

sns.lineplot(x = K, y = score);

fits[1]

df_cluster['cluster_label'] = fits[1].labels_
df_cluster.groupby(['cluster_label']).agg({
    'CustomerID' : 'count',
    'TransactionID' : 'mean',
    'Qty' : 'mean',})

